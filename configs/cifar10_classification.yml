training:
  n_epochs: 200
  batch_size: 128
  log_interval: 10
  snapshot_interval: 10

data:
  dataset: CIFAR10
  image_size: 32
  channels: 3
  num_classes: 10
  augmentation: true

model:
  n_layers: 19
  latent_size: 1
  n_subsampling: 2
  act_norm: false
  rgb_last: true
  pad_zero: true
  batch_norm: true

optim:
  optimizer: Adam
  lr: 0.001
  beta1: 0.9
  weight_decay: 0.0001
  amsgrad: true
  eps: 0.0001
